{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embedding for Akada Iamong\n",
      "No face detected for Akaradej Sukchan\n",
      "Saved embedding for Apiwat Rattanaphan\n",
      "Saved embedding for Apiwit Buachan\n",
      "Saved embedding for Ekapoj Suthiwong\n",
      "No face detected for Karanyapas Srikham\n",
      "Saved embedding for Nattawat Thakhamho\n",
      "No face detected for Noppawit Sabai\n",
      "Saved embedding for Panupong Sitthiprom\n",
      "Saved embedding for Peerakarn Phraphinyokul\n",
      "Saved embedding for Phacharadanai Rossoda\n",
      "No face detected for Phuri Khamfei\n",
      "Saved embedding for Phurin Rueannimit\n",
      "Saved embedding for Sittikorn Thongdeenok\n",
      "Saved embedding for Thanaphum Hengarun\n",
      "Saved embedding for Thanapon Phetprapai\n",
      "No face detected for Thanwa Suktham\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# ตั้งค่า device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# โหลดโมเดล MTCNN และ InceptionResnetV1\n",
    "mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20, device=device)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# โฟลเดอร์ที่เก็บรูปถ่ายของนักเรียน\n",
    "student_images_folder = r\"D:\\Friend\\Super AI\\V89\\My Project\\facenet-pytorch-master\\data\\test_images\"\n",
    "\n",
    "# ลูปสร้าง embeddings สำหรับนักเรียนแต่ละคน\n",
    "for student_name in os.listdir(student_images_folder):\n",
    "    student_folder = os.path.join(student_images_folder, student_name)\n",
    "    \n",
    "    # ตรวจสอบว่ามีโฟลเดอร์รูปภาพของนักเรียน\n",
    "    if os.path.isdir(student_folder):\n",
    "        embeddings_list = []\n",
    "\n",
    "        # ลูปสำหรับแต่ละรูปภาพในโฟลเดอร์\n",
    "        for image_name in os.listdir(student_folder):\n",
    "            image_path = os.path.join(student_folder, image_name)\n",
    "            img = Image.open(image_path)\n",
    "\n",
    "            # ใช้ MTCNN เพื่อตัดภาพใบหน้า\n",
    "            face = mtcnn(img)\n",
    "\n",
    "            if face is not None:\n",
    "                # สร้าง embeddings สำหรับใบหน้านั้น\n",
    "                face_embedding = resnet(face.unsqueeze(0).to(device)).detach()\n",
    "\n",
    "                # เก็บ embeddings ไว้ในรายการ\n",
    "                embeddings_list.append(face_embedding)\n",
    "\n",
    "        # หาค่าเฉลี่ยของ embeddings (ในกรณีที่มีหลายรูป)\n",
    "        if embeddings_list:\n",
    "            student_embedding = torch.mean(torch.stack(embeddings_list), dim=0)\n",
    "            \n",
    "            # บันทึก embeddings ลงไฟล์ .pt\n",
    "            torch.save(student_embedding, f\"{student_name}_embedding.pt\")\n",
    "            print(f\"Saved embedding for {student_name}\")\n",
    "        else:\n",
    "            print(f\"No face detected for {student_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     75\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m model(face_tensor)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m---> 76\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[43mrecognize_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_face_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_face_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Draw name on the frame\u001b[39;00m\n\u001b[0;32m     80\u001b[0m text_position \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(box[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Position to draw the name above the rectangle\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m, in \u001b[0;36mrecognize_face\u001b[1;34m(embedding, known_face_embeddings, known_face_names, threshold)\u001b[0m\n\u001b[0;32m     44\u001b[0m min_distance_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(distances)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distances[min_distance_index] \u001b[38;5;241m<\u001b[39m threshold:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mknown_face_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmin_distance_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Determine if an NVIDIA GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the face recognition model\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "mtcnn = MTCNN(keep_all=True, device=device)  # Initialize MTCNN for face detection\n",
    "\n",
    "# Define the directory containing images of known faces\n",
    "known_faces_dir = r'D:\\Friend\\Super AI\\V89\\My Project\\facenet-pytorch-master\\data\\test_images_aligned'  # Change this to your directory\n",
    "known_face_names = []\n",
    "known_face_embeddings = []\n",
    "\n",
    "# Loop through each person in the directory\n",
    "for person_name in os.listdir(known_faces_dir):\n",
    "    person_dir = os.path.join(known_faces_dir, person_name)\n",
    "    \n",
    "    if os.path.isdir(person_dir):  # Ensure it's a directory\n",
    "        known_face_names.append(person_name)  # Add person's name\n",
    "\n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            image = Image.open(image_path).convert('RGB')  # Load and convert image\n",
    "            image = image.resize((160, 160))  # Resize to (160, 160) for FaceNet\n",
    "            image_tensor = torch.tensor(np.array(image)).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "            \n",
    "            # Compute embedding\n",
    "            with torch.no_grad():\n",
    "                embedding = model(image_tensor).cpu()\n",
    "                known_face_embeddings.append(embedding)\n",
    "\n",
    "# Convert list of embeddings to a tensor for easier comparison later\n",
    "known_face_embeddings = torch.stack(known_face_embeddings)\n",
    "\n",
    "# Function to recognize faces\n",
    "def recognize_face(embedding, known_face_embeddings, known_face_names, threshold=0.8):\n",
    "    distances = [torch.norm(embedding - known_face_embedding).item() for known_face_embedding in known_face_embeddings]\n",
    "    min_distance_index = np.argmin(distances)\n",
    "    if distances[min_distance_index] < threshold:\n",
    "        return known_face_names[min_distance_index]\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Define the directory containing images to be processed\n",
    "image_dir = r'D:\\Friend\\Super AI\\V89\\My Project\\facenet-pytorch-master\\data\\test_images_aligned\\Panupong Sitthiprom'  # Change this to your directory\n",
    "output_dir = 'processed_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each image in the directory\n",
    "for image_name in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, _ = mtcnn.detect(image)\n",
    "    \n",
    "    # Draw faces and names\n",
    "    image_draw = image.copy()\n",
    "    draw = ImageDraw.Draw(image_draw)\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            draw.rectangle(box.tolist(), outline=(255, 0, 0), width=6)  # Draw rectangle around face\n",
    "            # Get the face region for recognition\n",
    "            face_region = np.array(image)[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "            face_region = cv2.resize(face_region, (160, 160))  # Resize for FaceNet\n",
    "            face_tensor = torch.tensor(face_region).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0\n",
    "            \n",
    "            # Get embedding and recognize\n",
    "            with torch.no_grad():\n",
    "                embedding = model(face_tensor).cpu()\n",
    "                identity = recognize_face(embedding, known_face_embeddings, known_face_names)\n",
    "            \n",
    "\n",
    "            # Draw name on the frame\n",
    "            text_position = (int(box[0]), int(box[1]) - 10)  # Position to draw the name above the rectangle\n",
    "            draw.text(text_position, identity, fill=(255, 0, 0))  # Draw name\n",
    "            \n",
    "            # Draw name on the image\n",
    "            #font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            #text_position = (int(box[0]), int(box[1]) - 10)  # Position to draw the name above the rectangle\n",
    "           # cv2.putText(np.array(image_draw), identity, text_position, font, 1.0, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Save the processed image\n",
    "    output_path = os.path.join(output_dir, image_name)\n",
    "    image_draw.save(output_path)\n",
    "    print(f\"Saved processed image: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
